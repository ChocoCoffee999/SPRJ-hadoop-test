# Master 접속 (클러스터 내 제출이면 서비스명, 외부/다른 디바이스에서면 192.168.0.2)
spark.master                       spark://192.168.0.2:7077

# 이벤트 로그 (HDFS에 /spark-events 만들어 두기)
spark.eventLog.enabled             true
spark.eventLog.dir                 hdfs://192.168.0.2:8020/spark-events
spark.hadoop.fs.defaultFS          hdfs://192.168.0.2:8020

# 셔플/네트워킹: 다중 디바이스 환경에서 포트 고정
spark.shuffle.service.enabled      true
spark.shuffle.service.port         7337
spark.blockManager.port            6060
spark.driver.blockManager.port     6061
spark.executor.port                6062
spark.driver.port                  7079

# 대용량 XML 입수/셔플 병렬도 (시작값)
spark.default.parallelism          512
spark.sql.shuffle.partitions       512
spark.sql.files.maxPartitionBytes  134217728
spark.hadoop.mapreduce.input.fileinputformat.split.minsize 134217728

# 실행기/드라이버 리소스(테스트값, 작업에 맞게 조절)
spark.executor.cores               4
spark.executor.memory              12g
spark.executor.memoryOverhead      1536m
spark.driver.memory                2g

# (옵션) 네트워크 타임아웃 여유
spark.network.timeout              120s
spark.rpc.askTimeout               120s

spark.driverEnv.HADOOP_USER_NAME=spark
spark.executorEnv.HADOOP_USER_NAME=spark